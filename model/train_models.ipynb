{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a89ec3b",
   "metadata": {},
   "source": [
    "# Breast Cancer Classification - Model Training Notebook\n",
    "\n",
    "**Models Implemented:**\n",
    "1. Logistic Regression\n",
    "2. Decision Tree Classifier\n",
    "3. K-Nearest Neighbors (KNN)\n",
    "4. Naive Bayes\n",
    "5. Random Forest\n",
    "6. XGBoost\n",
    "\n",
    "**Metrics Evaluated:**\n",
    "- Accuracy\n",
    "- AUC Score\n",
    "- Precision\n",
    "- Recall\n",
    "- F1-Score\n",
    "- Matthews Correlation Coefficient (MCC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a113d38",
   "metadata": {},
   "source": [
    "## 1. Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e82c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Scikit-learn imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import (accuracy_score, roc_auc_score, precision_score, \n",
    "                             recall_score, f1_score, matthews_corrcoef,\n",
    "                             confusion_matrix, classification_report)\n",
    "\n",
    "# Classification models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8972e8",
   "metadata": {},
   "source": [
    "## 2. Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e176e82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target classes: ['B' 'M']\n",
      "\n",
      " Dataset loaded successfully\n",
      "  - Features shape: (569, 30)\n",
      "  - Number of samples: 569\n",
      "  - Number of features: 30\n",
      "\n",
      "Class distribution:\n",
      "  - Benign (0): 357 samples (62.7%)\n",
      "  - Malignant (1): 212 samples (37.3%)\n"
     ]
    }
   ],
   "source": [
    "def load_data(filepath='breast-cancer.csv'):\n",
    "    \"\"\"Load and prepare the breast cancer dataset from CSV\"\"\"\n",
    "    df = pd.read_csv(filepath)\n",
    "    \n",
    "    # Drop ID column if exists\n",
    "    if 'id' in df.columns:\n",
    "        df = df.drop('id', axis=1)\n",
    "    \n",
    "    # Separate features and target\n",
    "    X = df.drop('diagnosis', axis=1)\n",
    "    y = df['diagnosis']\n",
    "    \n",
    "    # Encode target variable (M=1, B=0)\n",
    "    le = LabelEncoder()\n",
    "    y = le.fit_transform(y)\n",
    "    \n",
    "    print(f\"Target classes: {le.classes_}\")\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "# Load the dataset\n",
    "X, y = load_data()\n",
    "print(f\"\\n Dataset loaded successfully\")\n",
    "print(f\"  - Features shape: {X.shape}\")\n",
    "print(f\"  - Number of samples: {X.shape[0]}\")\n",
    "print(f\"  - Number of features: {X.shape[1]}\")\n",
    "\n",
    "# Display class distribution\n",
    "y_series = pd.Series(y)\n",
    "print(f\"\\nClass distribution:\")\n",
    "print(f\"  - Benign (0): {(y == 0).sum()} samples ({(y == 0).sum()/len(y)*100:.1f}%)\")\n",
    "print(f\"  - Malignant (1): {(y == 1).sum()} samples ({(y == 1).sum()/len(y)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292fe65a",
   "metadata": {},
   "source": [
    "### Split and Scale Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2401a5cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting data into training and testing sets (80-20 split)\n",
      "\n",
      " Data split done successfully\n",
      "  - Training set shape: (455, 30)\n",
      "  - Test set shape: (114, 30)\n",
      "  - Features scaled using StandardScaler\n"
     ]
    }
   ],
   "source": [
    "def split_data(X, y, test_size=0.2, random_state=42):\n",
    "    \"\"\"Split data into training and testing sets\"\"\"\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=random_state, stratify=y\n",
    "    )\n",
    "    \n",
    "    # Scale the features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    return X_train_scaled, X_test_scaled, y_train, y_test, scaler\n",
    "\n",
    "# Split and scale data\n",
    "print(\"Splitting data into training and testing sets (80-20 split)\")\n",
    "X_train, X_test, y_train, y_test, scaler = split_data(X, y)\n",
    "\n",
    "print(f\"\\n Data split done successfully\")\n",
    "print(f\"  - Training set shape: {X_train.shape}\")\n",
    "print(f\"  - Test set shape: {X_test.shape}\")\n",
    "print(f\"  - Features scaled using StandardScaler\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe174f2b",
   "metadata": {},
   "source": [
    "## 3. Define Models Configuration\n",
    "\n",
    "Initializing all 6 classification models with optimal parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b74b92b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models initialized:\n",
      "  - Logistic Regression\n",
      "  - Decision Tree\n",
      "  - KNN\n",
      "  - Naive Bayes\n",
      "  - Random Forest\n",
      "  - XGBoost\n"
     ]
    }
   ],
   "source": [
    "def calculate_metrics(y_true, y_pred, y_pred_proba):\n",
    "    \"\"\"Calculate all evaluation metrics\"\"\"\n",
    "    metrics = {\n",
    "        'Accuracy': accuracy_score(y_true, y_pred),\n",
    "        'AUC': roc_auc_score(y_true, y_pred_proba),\n",
    "        'Precision': precision_score(y_true, y_pred),\n",
    "        'Recall': recall_score(y_true, y_pred),\n",
    "        'F1': f1_score(y_true, y_pred),\n",
    "        'MCC': matthews_corrcoef(y_true, y_pred)\n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "# Initialize models\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
    "    'KNN': KNeighborsClassifier(n_neighbors=5),\n",
    "    'Naive Bayes': GaussianNB(),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'XGBoost': xgb.XGBClassifier(n_estimators=100, random_state=42, use_label_encoder=False, verbosity=0)\n",
    "}\n",
    "\n",
    "print(\"Models initialized:\")\n",
    "for model_name in models.keys():\n",
    "    print(f\"  - {model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d07b26",
   "metadata": {},
   "source": [
    "## 4. Train the Models\n",
    "\n",
    "Train all 6 classification models on the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36452334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "TRAINING ALL MODELS\n",
      "======================================================================\n",
      "\n",
      " ----- Logistic Regression -----\n",
      "    Accuracy: 0.9649\n",
      "    AUC Score: 0.9960\n",
      "    Precision: 0.9750\n",
      "    Recall: 0.9286\n",
      "    F1-Score: 0.9512\n",
      "    MCC Score: 0.9245\n",
      "    Training time: 0.0251s\n",
      "\n",
      " ----- Decision Tree -----\n",
      "    Accuracy: 0.9298\n",
      "    AUC Score: 0.9246\n",
      "    Precision: 0.9048\n",
      "    Recall: 0.9048\n",
      "    F1-Score: 0.9048\n",
      "    MCC Score: 0.8492\n",
      "    Training time: 0.0203s\n",
      "\n",
      " ----- KNN -----\n",
      "    Accuracy: 0.9561\n",
      "    AUC Score: 0.9823\n",
      "    Precision: 0.9744\n",
      "    Recall: 0.9048\n",
      "    F1-Score: 0.9383\n",
      "    MCC Score: 0.9058\n",
      "    Training time: 0.0275s\n",
      "\n",
      " ----- Naive Bayes -----\n",
      "    Accuracy: 0.9211\n",
      "    AUC Score: 0.9891\n",
      "    Precision: 0.9231\n",
      "    Recall: 0.8571\n",
      "    F1-Score: 0.8889\n",
      "    MCC Score: 0.8292\n",
      "    Training time: 0.0154s\n",
      "\n",
      " ----- Random Forest -----\n",
      "    Accuracy: 0.9737\n",
      "    AUC Score: 0.9929\n",
      "    Precision: 1.0000\n",
      "    Recall: 0.9286\n",
      "    F1-Score: 0.9630\n",
      "    MCC Score: 0.9442\n",
      "    Training time: 0.2099s\n",
      "\n",
      " ----- XGBoost -----\n",
      "    Accuracy: 0.9737\n",
      "    AUC Score: 0.9940\n",
      "    Precision: 1.0000\n",
      "    Recall: 0.9286\n",
      "    F1-Score: 0.9630\n",
      "    MCC Score: 0.9442\n",
      "    Training time: 0.0668s\n",
      "\n",
      "======================================================================\n",
      "✓ ALL MODELS TRAINED SUCCESSFULLY!\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"TRAINING ALL MODELS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "results = {}\n",
    "training_times = {}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    start_time = time.time()\n",
    "    \n",
    "    print(f\"\\n ----- {model_name} -----\")\n",
    "    \n",
    "    # Train model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predictions on test set\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Calculate metrics\n",
    "    metrics = calculate_metrics(y_test, y_pred, y_pred_proba)\n",
    "    \n",
    "    # Confusion matrix and classification report\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    cr = classification_report(y_test, y_pred, output_dict=True)\n",
    "    \n",
    "    training_time = time.time() - start_time\n",
    "    training_times[model_name] = training_time\n",
    "    \n",
    "    results[model_name] = {\n",
    "        'model': model,\n",
    "        'metrics': metrics,\n",
    "        'confusion_matrix': cm,\n",
    "        'classification_report': cr,\n",
    "        'y_pred': y_pred,\n",
    "        'y_pred_proba': y_pred_proba\n",
    "    }\n",
    "    \n",
    "    print(f\"    Training time: {training_time:.4f}s\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"✓ ALL MODELS TRAINED SUCCESSFULLY!\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b855b1df",
   "metadata": {},
   "source": [
    "## 5. Evaluate Model Performance\n",
    "\n",
    "Display comprehensive evaluation metrics for all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e54b88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "MODEL PERFORMANCE COMPARISON\n",
      "====================================================================================================\n",
      "              Model  Accuracy      AUC  Precision   Recall       F1      MCC\n",
      "Logistic Regression  0.964912 0.996032   0.975000 0.928571 0.951220 0.924518\n",
      "      Decision Tree  0.929825 0.924603   0.904762 0.904762 0.904762 0.849206\n",
      "                KNN  0.956140 0.982308   0.974359 0.904762 0.938272 0.905824\n",
      "        Naive Bayes  0.921053 0.989087   0.923077 0.857143 0.888889 0.829162\n",
      "      Random Forest  0.973684 0.992890   1.000000 0.928571 0.962963 0.944155\n",
      "            XGBoost  0.973684 0.994048   1.000000 0.928571 0.962963 0.944155\n",
      "\n",
      "====================================================================================================\n",
      " TOP PERFORMERS\n",
      "====================================================================================================\n",
      "\n",
      "1️⃣ Highest Accuracy: Random Forest\n",
      "   Accuracy: 0.9737\n",
      "\n",
      "2️⃣ Highest AUC Score: Logistic Regression\n",
      "   AUC: 0.9960\n",
      "\n",
      "3️⃣ Highest F1-Score: Random Forest\n",
      "   F1: 0.9630\n"
     ]
    }
   ],
   "source": [
    "# Create results dataframe\n",
    "results_list = []\n",
    "for model_name, result in results.items():\n",
    "    row = {'Model': model_name}\n",
    "    row.update(result['metrics'])\n",
    "    results_list.append(row)\n",
    "\n",
    "results_df = pd.DataFrame(results_list)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"✓ MODELS EVALUATION COMPLETED!\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad372239",
   "metadata": {},
   "source": [
    "## 6. Save Trained Models\n",
    "\n",
    "Serialize and save all trained models to disk for deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cafb24e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "SAVING TRAINED MODELS\n",
      "======================================================================\n",
      " Saved Logistic Regression to model\\Logistic_Regression_model.pkl\n",
      " Saved Decision Tree to model\\Decision_Tree_model.pkl\n",
      " Saved KNN to model\\KNN_model.pkl\n",
      " Saved Naive Bayes to model\\Naive_Bayes_model.pkl\n",
      " Saved Random Forest to model\\Random_Forest_model.pkl\n",
      " Saved XGBoost to model\\XGBoost_model.pkl\n",
      "\n",
      " - All models saved successfully!\n"
     ]
    }
   ],
   "source": [
    "def save_models(results, model_dir='model'):\n",
    "    \"\"\"Save trained models to disk\"\"\"\n",
    "    if not os.path.exists(model_dir):\n",
    "        os.makedirs(model_dir)\n",
    "    \n",
    "    for model_name, result in results.items():\n",
    "        model_path = os.path.join(model_dir, f\"{model_name.replace(' ', '_')}_model.pkl\")\n",
    "        with open(model_path, 'wb') as f:\n",
    "            pickle.dump(result['model'], f)\n",
    "        print(f\" Saved {model_name} to {model_path}\")\n",
    "\n",
    "# Save all models\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"SAVING TRAINED MODELS\")\n",
    "print(\"=\" * 70)\n",
    "save_models(results)\n",
    "print(\"\\n - All models saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c8335e",
   "metadata": {},
   "source": [
    "## 7. Export Results\n",
    "\n",
    "Save evaluation metrics and test data to CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67271a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Results saved to model_results.csv\n",
      " Test data saved to test_data.csv\n",
      "\n",
      "======================================================================\n",
      "✅ TRAINING PIPELINE COMPLETED SUCCESSFULLY!\n",
      "======================================================================\n",
      "\n",
      "Generated Files:\n",
      "  - model_results.csv - Model evaluation metrics\n",
      "  - test_data.csv - Test dataset for Streamlit app\n",
      "  - model/ directory - Saved trained models\n",
      "\n",
      " Ready for deployment!\n"
     ]
    }
   ],
   "source": [
    "# Save results to CSV\n",
    "csv_file = 'model_results.csv'\n",
    "results_df.to_csv(csv_file, index=False)\n",
    "print(f\"\\n Results saved to {csv_file}\")\n",
    "\n",
    "# Save test data for Streamlit app\n",
    "test_data_path = 'test_data.csv'\n",
    "df = pd.read_csv('breast-cancer.csv')\n",
    "feature_names = [col for col in df.columns if col not in ['id', 'diagnosis']]\n",
    "X_test_df = pd.DataFrame(X_test, columns=feature_names)\n",
    "X_test_df['diagnosis'] = y_test\n",
    "X_test_df.to_csv(test_data_path, index=False)\n",
    "print(f\" Test data saved to {test_data_path}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"✅ TRAINING PIPELINE COMPLETED SUCCESSFULLY!\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nGenerated Files:\")\n",
    "print(f\"  - model_results.csv - Model evaluation metrics\")\n",
    "print(f\"  - test_data.csv - Test dataset for Streamlit app\")\n",
    "print(f\"  - model/ directory - Saved trained models\")\n",
    "print(f\"\\n Ready for deployment!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
